{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import functions    # my own functions which are used in more notebooks\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import numpy as np\n",
    "import tqdm\n",
    "import math\n",
    "import kds\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, RepeatedStratifiedKFold\n",
    "import gensim\n",
    "print((gensim.__version__))  \n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score,classification_report, accuracy_score,precision_score,recall_score\n",
    "from re import search\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from re import search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload cleaned abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_english = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"outputs/df_sw_tok_low_punc_lemm_v7.csv\").rename(columns = {'doi_x':'doi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "476175"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>abstract</th>\n",
       "      <th>doi</th>\n",
       "      <th>cord_uid</th>\n",
       "      <th>journal</th>\n",
       "      <th>license</th>\n",
       "      <th>authors</th>\n",
       "      <th>len</th>\n",
       "      <th>language</th>\n",
       "      <th>abstract_cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>OBJECTIVE: This retrospective chart review des...</td>\n",
       "      <td>10.1186/1471-2334-1-6</td>\n",
       "      <td>ug7v899j</td>\n",
       "      <td>BMC Infect Dis</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Madani, Tariq A; Al-Ghamdi, Aisha A</td>\n",
       "      <td>1158</td>\n",
       "      <td>en</td>\n",
       "      <td>retrospective chart review describes epidemiol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2000.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Inflammatory diseases of the respiratory tract...</td>\n",
       "      <td>10.1186/rr14</td>\n",
       "      <td>02tnwd4m</td>\n",
       "      <td>Respir Res</td>\n",
       "      <td>no-cc</td>\n",
       "      <td>Vliet, Albert van der; Eiserich, Jason P; Cros...</td>\n",
       "      <td>718</td>\n",
       "      <td>en</td>\n",
       "      <td>inflammatory disease respiratory tract commonl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Year  Month  \\\n",
       "0           0  2001.0    7.0   \n",
       "1           1  2000.0    8.0   \n",
       "\n",
       "                                            abstract                    doi  \\\n",
       "0  OBJECTIVE: This retrospective chart review des...  10.1186/1471-2334-1-6   \n",
       "1  Inflammatory diseases of the respiratory tract...           10.1186/rr14   \n",
       "\n",
       "   cord_uid         journal license  \\\n",
       "0  ug7v899j  BMC Infect Dis   no-cc   \n",
       "1  02tnwd4m      Respir Res   no-cc   \n",
       "\n",
       "                                             authors   len language  \\\n",
       "0                Madani, Tariq A; Al-Ghamdi, Aisha A  1158       en   \n",
       "1  Vliet, Albert van der; Eiserich, Jason P; Cros...   718       en   \n",
       "\n",
       "                                    abstract_cleaned  \n",
       "0  retrospective chart review describes epidemiol...  \n",
       "1  inflammatory disease respiratory tract commonl...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_all.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sady experimentů\n",
    "\n",
    "params1 = {\"train_year_of_citations\": 2017,\n",
    "          \"test_year_of_citations\": 2018,\n",
    "          \"min_train_year_published\":2016,\n",
    "          \"max_train_year_published\":2017,\n",
    "          \"min_test_year_published\":2018,\n",
    "          \"max_test_year_published\":2018,\n",
    "          \"embeddings_from_year\": 2016,\n",
    "          \"embeddings_to_year\": 2017}\n",
    "\n",
    "\n",
    "params2 = {\"train_year_of_citations\": 2018,\n",
    "          \"test_year_of_citations\": 2019,\n",
    "          \"min_train_year_published\":2017,\n",
    "          \"max_train_year_published\":2018,\n",
    "          \"min_test_year_published\":2019,\n",
    "          \"max_test_year_published\":2019,\n",
    "          \"embeddings_from_year\": 2017,\n",
    "          \"embeddings_to_year\": 2018}\n",
    "\n",
    "params3 = {\"train_year_of_citations\": 2019,\n",
    "          \"test_year_of_citations\": 2020,\n",
    "          \"min_train_year_published\":2018,\n",
    "          \"max_train_year_published\":2019,\n",
    "          \"min_test_year_published\":2020,\n",
    "          \"max_test_year_published\":2020,\n",
    "          \"embeddings_from_year\": 2018,\n",
    "          \"embeddings_to_year\": 2019}\n",
    "\n",
    "\n",
    "params4 = {\"train_year_of_citations\": 2020,\n",
    "          \"test_year_of_citations\": 2021,\n",
    "          \"min_train_year_published\":2019,\n",
    "          \"max_train_year_published\":2020,\n",
    "          \"min_test_year_published\":2020,\n",
    "          \"max_test_year_published\":2020,\n",
    "          \"embeddings_from_year\": 2019,\n",
    "          \"embeddings_to_year\": 2020}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_experiments = [params1, params2, params3, params4 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target\n",
      "0    7126\n",
      "1    5640\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    7957\n",
      "1    6454\n",
      "Name: count, dtype: int64\n",
      "2329\n",
      "799\n",
      "(2329, 9431)\n",
      "799\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4430/4430 [00:02<00:00, 1555.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9431\n",
      "[1.0, 0.19, 0.17, 0.15, 0.13, 0.11, 0.09, 0.07, 0.05, 0.03, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2329/2329 [00:08<00:00, 266.07it/s]\n",
      "100%|██████████| 2329/2329 [00:08<00:00, 268.66it/s]\n",
      "100%|██████████| 799/799 [00:03<00:00, 248.95it/s]\n",
      "100%|██████████| 799/799 [00:03<00:00, 249.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.19, 0.17, 0.15, 0.13, 0.11, 0.09, 0.07, 0.05, 0.03, 0.01]\n",
      "target\n",
      "0    7957\n",
      "1    6454\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    9189\n",
      "1    7444\n",
      "Name: count, dtype: int64\n",
      "2393\n",
      "1028\n",
      "(2393, 9637)\n",
      "1028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3991/3991 [00:03<00:00, 1158.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9637\n",
      "[1.0, 0.19, 0.17, 0.15, 0.13, 0.11, 0.09, 0.07, 0.05, 0.03, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2393/2393 [00:09<00:00, 264.56it/s]\n",
      "100%|██████████| 2393/2393 [00:09<00:00, 261.93it/s]\n",
      "100%|██████████| 1028/1028 [00:04<00:00, 243.56it/s]\n",
      "100%|██████████| 1028/1028 [00:04<00:00, 245.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.19, 0.17, 0.15, 0.13, 0.11, 0.09, 0.07, 0.05, 0.03, 0.01]\n",
      "target\n",
      "0    9189\n",
      "1    7444\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    22317\n",
      "1    17775\n",
      "Name: count, dtype: int64\n",
      "2816\n",
      "20620\n",
      "(2816, 10616)\n",
      "20620\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 945/945 [00:01<00:00, 876.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10616\n",
      "[1.0, 0.19, 0.17, 0.15, 0.13, 0.11, 0.09, 0.07, 0.05, 0.03, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2816/2816 [00:11<00:00, 255.20it/s]\n",
      "100%|██████████| 2816/2816 [00:11<00:00, 252.91it/s]\n",
      "100%|██████████| 20620/20620 [01:25<00:00, 240.12it/s]\n",
      "100%|██████████| 20620/20620 [01:25<00:00, 241.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.19, 0.17, 0.15, 0.13, 0.11, 0.09, 0.07, 0.05, 0.03, 0.01]\n",
      "target\n",
      "0    22317\n",
      "1    17775\n",
      "Name: count, dtype: int64\n",
      "target\n",
      "0    8576\n",
      "1    4996\n",
      "Name: count, dtype: int64\n",
      "23150\n",
      "8645\n",
      "(23150, 28050)\n",
      "8645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11874/11874 [00:30<00:00, 383.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "28050\n",
      "[1.0, 0.19, 0.17, 0.15, 0.13, 0.11, 0.09, 0.07, 0.05, 0.03, 0.01]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 23150/23150 [01:29<00:00, 259.68it/s]\n",
      "100%|██████████| 23150/23150 [01:28<00:00, 261.60it/s]\n",
      "100%|██████████| 8645/8645 [00:32<00:00, 268.72it/s]\n",
      "100%|██████████| 8645/8645 [00:32<00:00, 270.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 0.19, 0.17, 0.15, 0.13, 0.11, 0.09, 0.07, 0.05, 0.03, 0.01]\n"
     ]
    }
   ],
   "source": [
    "for params in list_experiments:\n",
    "\n",
    "    train_year_of_citations = params[\"train_year_of_citations\"]\n",
    "    test_year_of_citations = params[\"test_year_of_citations\"]  \n",
    "    min_train_year_published = params[\"min_train_year_published\"]\n",
    "    max_train_year_published = params[\"max_train_year_published\"]\n",
    "    min_test_year_published = params[\"min_test_year_published\"]\n",
    "    max_test_year_published = params[\"max_test_year_published\"]\n",
    "    embeddings_from_year = params[\"embeddings_from_year\"]\n",
    "    embeddings_to_year = params[\"embeddings_to_year\"]\n",
    "    classifier = \"lr\"  # or \"rf\"\n",
    "\n",
    "    # Add target flag for dataframe\n",
    "    train_df = functions.add_target_opencitatins_marginal(target_year = train_year_of_citations,\n",
    "                                                      df = df_all,target_col_name=\"target\")\n",
    "    test_df = functions.add_target_opencitatins_marginal(target_year = test_year_of_citations, \n",
    "                                                     df = df_all,target_col_name = \"target\")\n",
    "\n",
    "    # Train test split based on year of publication\n",
    "    train_df = train_df[(train_df['Year']<=max_train_year_published) & (train_df['Year']>= min_train_year_published)]\n",
    "    train_df = train_df.set_index(\"doi\")\n",
    "    print(len(train_df))\n",
    "\n",
    "    test_df = test_df[(test_df['Year']<=max_test_year_published) & (test_df['Year']>= min_test_year_published)] \n",
    "    test_df = test_df.set_index(\"doi\")\n",
    "    print(len(test_df))\n",
    "\n",
    "\n",
    "#######################################################################################################################\n",
    "############                                           BOW                                               #####################################################\n",
    "########################################################################################################################\n",
    "\n",
    "\n",
    "    cvec = CountVectorizer(analyzer = \"word\", \n",
    "                       tokenizer = None, \n",
    "                       ngram_range=(1,1), \n",
    "                       binary= True,\n",
    "                       min_df = 2,\n",
    "                      ) \n",
    "\n",
    "    matrix_bow_train = cvec.fit_transform(train_df['abstract_cleaned'])\n",
    "    tokens_bow_train = cvec.get_feature_names_out()\n",
    "\n",
    "    with open('outputs/classifier/train_'+str(train_year_of_citations)+'/tokens_bow_'+str(train_year_of_citations)+'.data', 'wb') as filehandle:\n",
    "        pickle.dump(tokens_bow_train, filehandle)\n",
    "    \n",
    "    matrix_bow_train_pd = pd.DataFrame.sparse.from_spmatrix(matrix_bow_train, columns = tokens_bow_train)\n",
    "    matrix_bow_train_pd = matrix_bow_train_pd[sorted(matrix_bow_train_pd.columns)]\n",
    "    print(matrix_bow_train.shape)\n",
    "\n",
    "    # for testing we need to have the same features like in training, not new, not less ! \n",
    "    matrix_bow_test = cvec.fit_transform(test_df['abstract_cleaned'])\n",
    "    tokens_bow_test = cvec.get_feature_names_out()\n",
    "    matrix_bow_test_pd = pd.DataFrame.sparse.from_spmatrix(matrix_bow_test, columns = tokens_bow_test)\n",
    "    print(len(matrix_bow_test_pd))\n",
    "    not_in_test = np.setdiff1d(tokens_bow_train,tokens_bow_test)\n",
    "    columns_in_both = list(set(tokens_bow_train) & set(tokens_bow_test))\n",
    "    matrix_bow_test_pd_without_new_col = matrix_bow_test_pd[columns_in_both]\n",
    "\n",
    "    for col in tqdm(not_in_test): \n",
    "        matrix_bow_test_pd_without_new_col[col] =  np.nan\n",
    "    print(len(matrix_bow_test_pd_without_new_col.columns))\n",
    "\n",
    "    matrix_bow_test_pd = matrix_bow_test_pd_without_new_col.fillna(0)\n",
    "    matrix_bow_test_pd = matrix_bow_test_pd[sorted(matrix_bow_test_pd.columns)]\n",
    "\n",
    "    X_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(matrix_bow_train_pd, train_df.target, test_size=0.2, random_state=1,stratify= train_df[\"target\"])\n",
    "    splitted_train_features = y_test_bow.reset_index().merge(train_df, on=\"doi\",how=\"left\")\n",
    "\n",
    "    # classifier\n",
    "    cf_bow_splitted_train = LogisticRegression(penalty = \"none\",random_state = 0).fit(X_train_bow, y_train_bow)\n",
    "    pickle.dump(cf_bow_splitted_train, open('outputs/classifier/train_'+str(train_year_of_citations)+'/lreg_bow_'+str(train_year_of_citations)+'.sav', 'wb'))\n",
    "    cf_bow_splitted_train_reg = LogisticRegression(random_state = 0).fit(X_train_bow, y_train_bow)\n",
    "    pickle.dump(cf_bow_splitted_train_reg, open('outputs/classifier/train_'+str(train_year_of_citations)+'/lreg_reg_bow_'+str(train_year_of_citations)+'.sav', 'wb'))\n",
    "\n",
    "\n",
    "    y_pred_bow_splitted_train = cf_bow_splitted_train.predict_proba(X_test_bow)[:,1]\n",
    "    y_pred_bow_whole_train = cf_bow_splitted_train.predict_proba(matrix_bow_train_pd)[:,1]\n",
    "    y_pred_bow_test = cf_bow_splitted_train.predict_proba(matrix_bow_test_pd)[:,1]\n",
    "\n",
    "\n",
    "    matrix_pred_real = [ \n",
    "             ('predictions whole train set', y_pred_bow_whole_train, train_df.target),\n",
    "             ('predictions splitted train set', y_pred_bow_splitted_train,y_test_bow),\n",
    "             ('predictions tested new month',y_pred_bow_test,test_df.target),\n",
    "             ]\n",
    "\n",
    "    # results\n",
    "    results_train = pd.DataFrame(zip(list( y_pred_bow_whole_train),list(train_df.target), list(train_df.Year), list(train_df.OpenCitations)),columns=[\"y_pred\",\"real\",\"Year\",\"OpenCitations\"])\n",
    "    results_splitted_train = pd.DataFrame(zip(list( y_pred_bow_splitted_train),list(y_test_bow), list(splitted_train_features.Year), list(splitted_train_features.OpenCitations)),columns=[\"y_pred\",\"real\",\"Year\",\"OpenCitations\"])\n",
    "    results_test = pd.DataFrame(zip(list( y_pred_bow_test),list(test_df.target), list(test_df.Year), list(test_df.OpenCitations)),columns=[\"y_pred\",\"real\",\"Year\",\"OpenCitations\"])\n",
    "\n",
    "\n",
    "    # Top x% with highest OpenCitations + x% of lowest citations\n",
    "    list_df = []\n",
    "    for results in [results_train,results_splitted_train, results_test]:\n",
    "        auc_list=[]\n",
    "        perc_list = [0.19,0.17,0.15,0.13,0.11,0.09,0.07,0.05,0.03,0.01] \n",
    "        for perc in perc_list:\n",
    "            auc_list.append(roc_auc_score(functions.x_first_last_val(results,perc).real.values, \n",
    "                                      functions.x_first_last_val(results,perc).y_pred.values\n",
    "                                     )\n",
    "                       )\n",
    "        auc_per_perc = pd.DataFrame(zip(auc_list,perc_list),columns=[\"auc\",\"perc\"])\n",
    "        list_df.append(auc_per_perc)\n",
    "\n",
    "    res_list = []\n",
    "    perc_list_1 = [1.0] + perc_list\n",
    "    print(perc_list_1)\n",
    "    \n",
    "    for frac in perc_list_1:\n",
    "        if frac == 1: \n",
    "            df_res = functions.resulted_matrics_table(matrix_pred_real,frac_articles=1)\n",
    "\n",
    "        if frac <1:\n",
    "            y_real_train = functions.x_first_last_val(results_train,frac).real.values\n",
    "            probs_train =functions.x_first_last_val(results_train,frac).y_pred.values\n",
    "            y_real_train_spl = functions.x_first_last_val(results_splitted_train,frac).real.values\n",
    "            probs_train_spl =functions.x_first_last_val(results_splitted_train,frac).y_pred.values\n",
    "            y_real_test = functions.x_first_last_val(results_test,frac).real.values\n",
    "            probs_test =functions.x_first_last_val(results_test,frac).y_pred.values\n",
    "\n",
    "            matrix_pred_real_2 = [ \n",
    "             ('predictions whole train set', probs_train, y_real_train),\n",
    "             ('predictions tested new month',probs_test,  y_real_test),\n",
    "              ('predictions splitted train set', probs_train_spl,y_real_train_spl)\n",
    "             ]\n",
    "        \n",
    "            df_res  = functions.resulted_matrics_table(matrix_pred_real_2,frac_articles=frac)\n",
    "        df_res[\"perc\"] = frac\n",
    "        res_list.append(df_res)    \n",
    "     \n",
    "    # output - accuracy on test set of BOW\n",
    "    res_all = pd.concat(res_list).pivot(index = \"perc\",columns='dataset_of_predictions', values=[\"AUC\",\"Accuracy\",\"Precision\",\"Recall\"])\n",
    "    res_all.to_csv('outputs/classifier/train_'+str(train_year_of_citations)+'/res_all_bow_'+str(train_year_of_citations)+'.csv')\n",
    "    \n",
    "    high_score_art_lr_bow = pd.DataFrame(list(zip(list(y_pred_bow_test), list(test_df.target.values), list(test_df.abstract.values),list(test_df.index),list(test_df.OpenCitations.values),list(test_df.Year.values) )),columns =[\"score\",\"target\",\"abstract\",\"doi\",\"OpenCitations\",\"Year\"])\n",
    "    high_score_art_lr_bow = high_score_art_lr_bow.sort_values(\"score\",ascending=False)\n",
    "    #high_score_art_lr_bow.to_csv('outputs/classifier/train_'+str(train_year_of_citations)+'/'+\"score_art_lr_bow.csv\")\n",
    "\n",
    "\n",
    "####################################################################################################################\n",
    "########################################               WORD2VEC                            #########################\n",
    "####################################################################################################################\n",
    "\n",
    "    if only_english:\n",
    "        model_w2v = gensim.models.Word2Vec.load(\"outputs/w2v/w2v_published_between_\"+str(embeddings_from_year) + \" and \"+ str(embeddings_to_year)+\".model\")\n",
    "\n",
    "    if not only_english:\n",
    "        model_w2v = gensim.models.Word2Vec.load(\"outputs/w2v/w2v_published_between_\"+str(embeddings_from_year) + \" and \"+ str(embeddings_to_year)+\".model\")\n",
    "\n",
    "    train_df[\"abstract_tokenized\"] = functions.tokenized_column(train_df.reset_index()[\"abstract_cleaned\"])\n",
    "    df_X_train_avg = functions.transform_to_document_vector(text_col_tokenized = train_df.reset_index().abstract_tokenized,model = model_w2v,index_col_list = list(train_df.index),agg_func = \"avg\").fillna(0)\n",
    "    df_X_train_sum = functions.transform_to_document_vector(text_col_tokenized = train_df.reset_index().abstract_tokenized,model = model_w2v,index_col_list = list(train_df.index),agg_func = \"sum\").fillna(0)\n",
    "\n",
    "    test_df[\"abstract_tokenized\"] = functions.tokenized_column(test_df.reset_index()[\"abstract_cleaned\"])\n",
    "    df_X_test_avg = functions.transform_to_document_vector(text_col_tokenized = test_df.reset_index().abstract_tokenized,model = model_w2v,index_col_list = list(test_df.index),agg_func = \"avg\").fillna(0)\n",
    "    df_X_test_sum = functions.transform_to_document_vector(text_col_tokenized = test_df.reset_index().abstract_tokenized,model = model_w2v,index_col_list = list(test_df.index),agg_func = \"sum\").fillna(0)\n",
    "\n",
    "\n",
    "    # USE SAME SET FOR COMPARING LIKE IN BOW !!!\n",
    "    X_train_w2v_avg = df_X_train_avg.reset_index().rename({\"index\":\"doi\"},axis=\"columns\").merge(y_train_bow.reset_index()[[\"doi\"]],how=\"right\",on=\"doi\").set_index(\"doi\")\n",
    "    X_test_w2v_avg = df_X_train_avg.reset_index().rename({\"index\":\"doi\"},axis=\"columns\").merge(y_test_bow.reset_index()[[\"doi\"]],how=\"right\",on=\"doi\").set_index(\"doi\")\n",
    "\n",
    "    X_train_w2v_sum = df_X_train_sum.reset_index().rename({\"index\":\"doi\"},axis=\"columns\").merge(y_train_bow.reset_index()[[\"doi\"]],how=\"right\",on=\"doi\").set_index(\"doi\")\n",
    "    X_test_w2v_sum = df_X_train_sum.reset_index().rename({\"index\":\"doi\"},axis=\"columns\").merge(y_test_bow.reset_index()[[\"doi\"]],how=\"right\",on=\"doi\").set_index(\"doi\")\n",
    "\n",
    "    y_train_w2v = y_train_bow\n",
    "    y_test_w2v = y_test_bow\n",
    "\n",
    "    if classifier == \"lr\":\n",
    "        cf_w2v_splitted_train_avg = LogisticRegression(penalty = \"none\",random_state = 0).fit(X_train_w2v_avg, y_train_w2v)\n",
    "        pickle.dump(cf_w2v_splitted_train_avg, open('outputs/classifier/train_'+str(train_year_of_citations)+'/'+'lreg_w2v_avg_'+str(train_year_of_citations)+'.sav', 'wb'))\n",
    "        cf_w2v_splitted_train_avg_reg = LogisticRegression(random_state = 0).fit(X_train_w2v_avg, y_train_w2v)\n",
    "        pickle.dump(cf_w2v_splitted_train_avg_reg, open('outputs/classifier/train_'+str(train_year_of_citations)+'/'+'lreg_reg_w2v_avg_'+str(train_year_of_citations)+'.sav', 'wb'))\n",
    "        \n",
    "    if classifier == \"rf\":\n",
    "        cf_w2v_splitted_train_avg = RandomForestClassifier(random_state=0).fit(X_train_w2v_avg, y_train_w2v)\n",
    "        pickle.dump(cf_w2v_splitted_train_avg, open('outputs/classifier/train_'+str(train_year_of_citations)+'/'+'rf_w2v_avg_'+str(train_year_of_citations)+'.sav', 'wb'))\n",
    "    \n",
    "    y_pred_w2v_splitted_train_avg = cf_w2v_splitted_train_avg.predict_proba(X_test_w2v_avg)[:,1]\n",
    "    y_pred_w2v_whole_train_avg = cf_w2v_splitted_train_avg.predict_proba(df_X_train_avg)[:,1]\n",
    "    y_pred_w2v_test_avg = cf_w2v_splitted_train_avg.predict_proba(df_X_test_avg)[:,1]\n",
    "\n",
    "    splitted_train_features = y_test_w2v.reset_index().merge(train_df, on=\"doi\",how=\"left\")\n",
    "\n",
    "    results_train_w2v_avg = pd.DataFrame(zip(list( y_pred_w2v_whole_train_avg),list(train_df.target), list(train_df.Year), list(train_df.OpenCitations)),columns=[\"y_pred\",\"real\",\"Year\",\"OpenCitations\"])\n",
    "    results_splitted_train_w2v_avg = pd.DataFrame(zip(list( y_pred_w2v_splitted_train_avg),list(y_test_w2v), list(splitted_train_features.Year), list(splitted_train_features.OpenCitations)),columns=[\"y_pred\",\"real\",\"Year\",\"OpenCitations\"])\n",
    "    results_test_w2v_avg = pd.DataFrame(zip(list( y_pred_w2v_test_avg),list(test_df.target), list(test_df.Year), list(test_df.OpenCitations)),columns=[\"y_pred\",\"real\",\"Year\",\"OpenCitations\"])\n",
    "\n",
    "    matrix_pred_real_w2v = [ \n",
    "             ('predictions whole train set', y_pred_w2v_whole_train_avg, train_df.target),\n",
    "             ('predictions splitted train set', y_pred_w2v_splitted_train_avg,y_test_w2v),\n",
    "             ('predictions tested new month',y_pred_w2v_test_avg,test_df.target),\n",
    "             ]\n",
    "\n",
    "    # Top X% with highest OpenCitations + X% of lowest citations\n",
    "\n",
    "    list_df_avg = []\n",
    "    for results in [results_train_w2v_avg,results_splitted_train_w2v_avg, results_test_w2v_avg]:\n",
    "        auc_list=[]\n",
    "    \n",
    "        perc_list = [0.19,0.17,0.15,0.13,0.11,0.09,0.07,0.05,0.03,0.01]     \n",
    "        for perc in perc_list:\n",
    "            auc_list.append(roc_auc_score(functions.x_first_last_val(results,perc).real.values, functions.x_first_last_val(results,perc).y_pred.values) )\n",
    "        auc_per_perc = pd.DataFrame(zip(auc_list,perc_list),columns=[\"auc\",\"perc\"])\n",
    "        list_df_avg.append(auc_per_perc)\n",
    "    \n",
    "    res_list = []\n",
    "    perc_list_1 = [1.0] + perc_list\n",
    "    print(perc_list_1)\n",
    "\n",
    "    for frac in perc_list_1:\n",
    "        if frac == 1: \n",
    "            df_res = functions.resulted_matrics_table(matrix_pred_real_w2v,frac_articles=1)\n",
    "\n",
    "        if frac <1:\n",
    "            y_real_train = functions.x_first_last_val(results_train_w2v_avg,frac).real.values\n",
    "            probs_train =functions.x_first_last_val(results_train_w2v_avg,frac).y_pred.values\n",
    "            y_real_train_spl = functions.x_first_last_val(results_splitted_train_w2v_avg,frac).real.values\n",
    "            probs_train_spl =functions.x_first_last_val(results_splitted_train_w2v_avg,frac).y_pred.values\n",
    "            y_real_test = functions.x_first_last_val(results_test_w2v_avg,frac).real.values\n",
    "            probs_test =functions.x_first_last_val(results_test_w2v_avg,frac).y_pred.values\n",
    "\n",
    "            matrix_pred_real_2 = [ \n",
    "             ('predictions whole train set', probs_train, y_real_train),\n",
    "             ('predictions tested new month',probs_test,  y_real_test),\n",
    "              ('predictions splitted train set', probs_train_spl,y_real_train_spl)\n",
    "             ]\n",
    "    \n",
    "            df_res  = functions.resulted_matrics_table(matrix_pred_real_2,frac_articles=frac)\n",
    "        df_res[\"perc\"] = frac\n",
    "        res_list.append(df_res)    \n",
    "      \n",
    "    res_all = pd.concat(res_list).pivot(index = \"perc\",columns='dataset_of_predictions', values=[\"AUC\",\"Accuracy\",\"Precision\",\"Recall\"] )\n",
    "    res_all.to_csv('outputs/classifier/train_'+str(train_year_of_citations)+'/res_all_w2v_avg_'+str(train_year_of_citations)+'.csv')\n",
    "\n",
    "    high_score_art_lr_w2v_avg = pd.DataFrame(list(zip(list(y_pred_w2v_test_avg), list(test_df.target.values), list(test_df.abstract.values),list(test_df.index),list(test_df.OpenCitations.values),list(test_df.Year.values) )),columns =[\"score\",\"target\",\"abstract\",\"doi\",\"OpenCitations\",\"Year\"])\n",
    "    high_score_art_lr_w2v_avg = high_score_art_lr_w2v_avg.sort_values(\"score\",ascending=False)\n",
    "    #high_score_art_lr_w2v_avg.to_csv('outputs/classifier/train_'+str(train_year_of_citations)+'/'+'score_art_lr_w2v_avg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Table with AUC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_train_years = [2017,2018,2019,2020]\n",
    "perc = [\"0.05\",\"1.0\"]\n",
    "\n",
    "fin_list = []\n",
    "for train_year in list_train_years:\n",
    "    \n",
    "    bow = pd.read_csv('outputs/classifier/train_'+str(train_year)+'/'+\"res_all_bow_\"+str(train_year)+\".csv\")\n",
    "    bow.columns = bow.iloc[0]\n",
    "    bow = bow.iloc[2:]\n",
    "    auc_bow = bow.iloc[:, 0:4]\n",
    "    auc_bow = auc_bow[auc_bow[\"dataset_of_predictions\"].isin(perc)]\n",
    "    auc_bow[\"Train/Test years\"] = str(train_year-1)+\"+\"+str(train_year)+\"/\"+str(train_year+1)\n",
    "    auc_bow[\"model\"] = \"bow\"\n",
    "    \n",
    "    w2v = pd.read_csv('outputs/classifier/train_'+str(train_year)+'/'+\"res_all_w2v_avg_\"+str(train_year)+\".csv\")\n",
    "    w2v.columns = w2v.iloc[0]\n",
    "    w2v = w2v.iloc[2:]\n",
    "    auc_w2v = w2v.iloc[:, 0:4]\n",
    "    auc_w2v = auc_w2v[auc_w2v[\"dataset_of_predictions\"].isin(perc)]\n",
    "    auc_w2v[\"Train/Test years\"] = str(train_year-1)+\"+\"+str(train_year)+\"/\"+str(train_year+1)\n",
    "    auc_w2v[\"model\"] = \"w2v\"\n",
    "    \n",
    "    fin = pd.concat([auc_bow,auc_w2v]).pivot(index=[\"Train/Test years\",\"dataset_of_predictions\"],columns = \"model\",\n",
    "                                             values=[\"predictions splitted train set\",\"predictions tested new month\",\"predictions whole train set\"])\n",
    "    fin_list.append(fin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th colspan=\"2\" halign=\"left\">predictions splitted train set</th>\n",
       "      <th colspan=\"2\" halign=\"left\">predictions tested new month</th>\n",
       "      <th colspan=\"2\" halign=\"left\">predictions whole train set</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>bow</th>\n",
       "      <th>w2v</th>\n",
       "      <th>bow</th>\n",
       "      <th>w2v</th>\n",
       "      <th>bow</th>\n",
       "      <th>w2v</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Train/Test years</th>\n",
       "      <th>dataset_of_predictions</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2016+2017/2018</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.5954631379962193</td>\n",
       "      <td>0.7145557655954631</td>\n",
       "      <td>0.755</td>\n",
       "      <td>0.7687499999999999</td>\n",
       "      <td>0.9809007134363852</td>\n",
       "      <td>0.8195600475624256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5489338076148532</td>\n",
       "      <td>0.6110891536333352</td>\n",
       "      <td>0.5621389275286037</td>\n",
       "      <td>0.5839943857538503</td>\n",
       "      <td>0.9360476414284294</td>\n",
       "      <td>0.6932079405393519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2017+2018/2019</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.7934027777777778</td>\n",
       "      <td>0.7239583333333334</td>\n",
       "      <td>0.5922722029988465</td>\n",
       "      <td>0.6778162245290273</td>\n",
       "      <td>0.9354166666666667</td>\n",
       "      <td>0.7775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.6126668808452916</td>\n",
       "      <td>0.6295066752338117</td>\n",
       "      <td>0.5481855350559098</td>\n",
       "      <td>0.5808220320036983</td>\n",
       "      <td>0.9475996823898021</td>\n",
       "      <td>0.6637065968496502</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2018+2019/2020</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.7538265306122449</td>\n",
       "      <td>0.7270408163265306</td>\n",
       "      <td>0.5160612665939766</td>\n",
       "      <td>0.4671657756023033</td>\n",
       "      <td>0.9641869121271566</td>\n",
       "      <td>0.7525275388561943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.596755143510287</td>\n",
       "      <td>0.6064516129032258</td>\n",
       "      <td>0.506827404654271</td>\n",
       "      <td>0.4869826714004774</td>\n",
       "      <td>0.9356083763317274</td>\n",
       "      <td>0.6702756788040334</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">2019+2020/2021</th>\n",
       "      <th>0.05</th>\n",
       "      <td>0.6447588436385256</td>\n",
       "      <td>0.8343304102259215</td>\n",
       "      <td>0.7339731224279837</td>\n",
       "      <td>0.761016803840878</td>\n",
       "      <td>0.9320250208059278</td>\n",
       "      <td>0.8319425428273988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>0.5723010887772194</td>\n",
       "      <td>0.6752306989492919</td>\n",
       "      <td>0.6493484744929164</td>\n",
       "      <td>0.622964436036656</td>\n",
       "      <td>0.9125345414619969</td>\n",
       "      <td>0.6714612204043875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        predictions splitted train set  \\\n",
       "model                                                              bow   \n",
       "Train/Test years dataset_of_predictions                                  \n",
       "2016+2017/2018   0.05                               0.5954631379962193   \n",
       "                 1.0                                0.5489338076148532   \n",
       "2017+2018/2019   0.05                               0.7934027777777778   \n",
       "                 1.0                                0.6126668808452916   \n",
       "2018+2019/2020   0.05                               0.7538265306122449   \n",
       "                 1.0                                 0.596755143510287   \n",
       "2019+2020/2021   0.05                               0.6447588436385256   \n",
       "                 1.0                                0.5723010887772194   \n",
       "\n",
       "                                                             \\\n",
       "model                                                   w2v   \n",
       "Train/Test years dataset_of_predictions                       \n",
       "2016+2017/2018   0.05                    0.7145557655954631   \n",
       "                 1.0                     0.6110891536333352   \n",
       "2017+2018/2019   0.05                    0.7239583333333334   \n",
       "                 1.0                     0.6295066752338117   \n",
       "2018+2019/2020   0.05                    0.7270408163265306   \n",
       "                 1.0                     0.6064516129032258   \n",
       "2019+2020/2021   0.05                    0.8343304102259215   \n",
       "                 1.0                     0.6752306989492919   \n",
       "\n",
       "                                        predictions tested new month  \\\n",
       "model                                                            bow   \n",
       "Train/Test years dataset_of_predictions                                \n",
       "2016+2017/2018   0.05                                          0.755   \n",
       "                 1.0                              0.5621389275286037   \n",
       "2017+2018/2019   0.05                             0.5922722029988465   \n",
       "                 1.0                              0.5481855350559098   \n",
       "2018+2019/2020   0.05                             0.5160612665939766   \n",
       "                 1.0                               0.506827404654271   \n",
       "2019+2020/2021   0.05                             0.7339731224279837   \n",
       "                 1.0                              0.6493484744929164   \n",
       "\n",
       "                                                             \\\n",
       "model                                                   w2v   \n",
       "Train/Test years dataset_of_predictions                       \n",
       "2016+2017/2018   0.05                    0.7687499999999999   \n",
       "                 1.0                     0.5839943857538503   \n",
       "2017+2018/2019   0.05                    0.6778162245290273   \n",
       "                 1.0                     0.5808220320036983   \n",
       "2018+2019/2020   0.05                    0.4671657756023033   \n",
       "                 1.0                     0.4869826714004774   \n",
       "2019+2020/2021   0.05                     0.761016803840878   \n",
       "                 1.0                      0.622964436036656   \n",
       "\n",
       "                                        predictions whole train set  \\\n",
       "model                                                           bow   \n",
       "Train/Test years dataset_of_predictions                               \n",
       "2016+2017/2018   0.05                            0.9809007134363852   \n",
       "                 1.0                             0.9360476414284294   \n",
       "2017+2018/2019   0.05                            0.9354166666666667   \n",
       "                 1.0                             0.9475996823898021   \n",
       "2018+2019/2020   0.05                            0.9641869121271566   \n",
       "                 1.0                             0.9356083763317274   \n",
       "2019+2020/2021   0.05                            0.9320250208059278   \n",
       "                 1.0                             0.9125345414619969   \n",
       "\n",
       "                                                             \n",
       "model                                                   w2v  \n",
       "Train/Test years dataset_of_predictions                      \n",
       "2016+2017/2018   0.05                    0.8195600475624256  \n",
       "                 1.0                     0.6932079405393519  \n",
       "2017+2018/2019   0.05                                0.7775  \n",
       "                 1.0                     0.6637065968496502  \n",
       "2018+2019/2020   0.05                    0.7525275388561943  \n",
       "                 1.0                     0.6702756788040334  \n",
       "2019+2020/2021   0.05                    0.8319425428273988  \n",
       "                 1.0                     0.6714612204043875  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat(fin_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
