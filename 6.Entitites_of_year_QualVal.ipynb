{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.1.2\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gensim\n",
    "import operator\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "print((gensim.__version__))  # needed 3.8.3   -> pip install gensim==3.8.3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import functions\n",
    "import re\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload sources - trained models, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_year_of_citations = 2021\n",
    "\n",
    "# which articles based on year of publication will be selected for training and testing\n",
    "min_train_year_published = 2019\n",
    "max_train_year_published = 2020\n",
    "min_pred_year_published = 2022\n",
    "max_pred_year_published = 2022\n",
    "\n",
    "embeddings_from_year = 2019\n",
    "embeddings_to_year = 2020\n",
    "\n",
    "classifier = \"lr\"  # or \"rf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"outputs/df_sw_tok_low_punc_lemm_v7.csv\").rename(columns = {'doi_x':'doi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_from = df_all[(df_all['Year']<=2022) & (df_all['Year']>=2021)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_w2v_avg = pickle.load(open('outputs/classifier/train_'+str(train_year_of_citations)+'/'+'lreg_w2v_avg_'+str(train_year_of_citations)+'.sav', 'rb'))\n",
    "model_w2v = gensim.models.Word2Vec.load(\"outputs/w2v/w2v_published_between_\"+str(embeddings_from_year) + \" and \"+ str(embeddings_to_year)+\".model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of lreg w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82402\n"
     ]
    }
   ],
   "source": [
    "#### words of word2vec model whole dictionary - based on published articles 2019-2022 \n",
    "words = model_w2v.wv.key_to_index.keys()\n",
    "we_dict = {word:model_w2v.wv[word] for word in words}\n",
    "words_list_total = pd.DataFrame(we_dict.items())\n",
    "print(len(words_list_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_of_word =  functions.score_of_word(model_w2v,lreg_w2v_avg).sort_values(by = [\"score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add cnt of articles and first year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cnt_info(score_of_word, df_all, top_n = 40000):\n",
    "\n",
    "    final_results_of_select = score_of_word[score_of_word[\"word\"].isin(list(words_list_total[0].values))]\n",
    "    df_all[\"abstract_cleaned_tok\"] = functions.tokenized_column(df_all[\"abstract_cleaned\"])\n",
    "    df_all_list_of_lists = list(df_all[\"abstract_cleaned_tok\"].values)\n",
    "\n",
    "    corpus = df_all.abstract_cleaned\n",
    "    words = ' '.join(corpus)\n",
    "    output = Counter(words.split()).most_common()\n",
    "    cnt_in_all_articles = pd.DataFrame(output,columns=[\"index\",\"cnt_in_all_articles\"])\n",
    "    \n",
    "    cnt = dict(Counter(chain.from_iterable(set(l) for l in df_all_list_of_lists)))\n",
    "    cnt_articles = pd.DataFrame(cnt,index=[\"cnt_of_articles\"]).transpose().reset_index()\n",
    "    \n",
    "    final_results_of_select = pd.merge(final_results_of_select, cnt_in_all_articles, left_on=  ['word'],\n",
    "                   right_on= ['index'], \n",
    "                   how = 'left')\n",
    "    \n",
    "    final_results_of_select = pd.merge(final_results_of_select, cnt_articles, left_on=  ['word'],\n",
    "                   right_on= ['index'], \n",
    "                   how = 'left')\n",
    "    \n",
    "    final_results_of_select = final_results_of_select[[\"word\",\"score\",\"cnt_in_all_articles\",\"cnt_of_articles\"]]\n",
    "    \n",
    "    top_df = final_results_of_select[:top_n]\n",
    " \n",
    "    return top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = add_cnt_info(score_of_word, df_all, top_n = 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add first year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_info_wo_target_w2(top_df, df_all, top_n = 40000):\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    cvec = CountVectorizer(analyzer = \"word\", tokenizer=lambda txt: txt.split(), \n",
    "                       ngram_range=(1,1),\n",
    "                       binary= True,\n",
    "                       min_df = 3\n",
    "                      ) \n",
    "    matrix_bow_train = cvec.fit_transform(df_all['abstract_cleaned'])\n",
    "    tokens_bow_train = cvec.get_feature_names_out()\n",
    "    matrix_bow_train_pd = pd.DataFrame.sparse.from_spmatrix(matrix_bow_train, columns = tokens_bow_train,index=df_all.Year)\n",
    "    matrix_bow_train_pd = matrix_bow_train_pd[[col for col in matrix_bow_train_pd.columns if col in list(top_df.word.values)]]\n",
    "    matrix_bow_train_pd = matrix_bow_train_pd.reset_index()\n",
    "    \n",
    "    for col in tqdm(matrix_bow_train_pd.columns[1:(int(top_n))]):\n",
    "        matrix_bow_train_pd[col] = matrix_bow_train_pd[col]*matrix_bow_train_pd['Year']\n",
    "        #matrix_bow_train_pd[col] = np.where(matrix_bow_train_pd[col]==1,matrix_bow_train_pd['Year'],0)\n",
    "        \n",
    "    matrix_bow_train_pd=matrix_bow_train_pd.mask(matrix_bow_train_pd==0)\n",
    "    matrix_bow_train_pd=matrix_bow_train_pd.fillna(10000)\n",
    "    min_df = matrix_bow_train_pd.min()\n",
    "\n",
    "    return pd.merge(top_df,min_df.reset_index(), left_on=['word'], right_on= ['index'],  how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berl03\\Anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py:523: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "C:\\Users\\berl03\\AppData\\Local\\Temp/ipykernel_12104/2031339013.py:13: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  matrix_bow_train_pd = matrix_bow_train_pd.reset_index()\n",
      "100%|██████████████████████████████████████████████████████████████████████████████| 4999/4999 [02:01<00:00, 41.10it/s]\n"
     ]
    }
   ],
   "source": [
    "score_of_word_with_info = score_info_wo_target_w2(top_df, df_all, top_n = len(top_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_of_word_with_info[\"quantile\"]=pd.cut(score_of_word_with_info.score, bins=10, right=True,labels=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"])\n",
    "score_of_word_with_info = score_of_word_with_info.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add relevant articles - articles with the highest number of words appeared in\n",
    "\n",
    "- from all articles 2019-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = score_of_word_with_info\n",
    "\n",
    "top_n = len(top_df)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(analyzer = \"word\", tokenizer=lambda txt: txt.split(), \n",
    "                       ngram_range=(1,1),\n",
    "                       binary= False,\n",
    "                       min_df = 1\n",
    "                      ) \n",
    "matrix_bow_train = cvec.fit_transform(df_all_from['abstract_cleaned'])\n",
    "tokens_bow_train = cvec.get_feature_names_out()\n",
    "matrix_bow_train_pd = pd.DataFrame.sparse.from_spmatrix(matrix_bow_train, columns = tokens_bow_train,index=df_all_from.doi)\n",
    "matrix_bow_train_pd = matrix_bow_train_pd[[col for col in matrix_bow_train_pd.columns if col in list(top_df.word.values)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\berl03\\AppData\\Local\\Temp/ipykernel_12104/2941236748.py:1: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead.  To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  matrix_bow_train_pd = matrix_bow_train_pd.reset_index()\n"
     ]
    }
   ],
   "source": [
    "matrix_bow_train_pd = matrix_bow_train_pd.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████| 4993/4993 [04:28<00:00, 18.63it/s]\n"
     ]
    }
   ],
   "source": [
    "top_dois = []\n",
    "top_cnt = []\n",
    "word_list = []\n",
    "for col in tqdm(matrix_bow_train_pd.columns[1:(int(top_n))]):\n",
    "    top = matrix_bow_train_pd[[col]+[\"doi\"]].sort_values(col,ascending=False)[:3]\n",
    "    top_dois.append(str(top[\"doi\"].values))\n",
    "    top_cnt.append(str(list(top[col].values)))\n",
    "    word_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = pd.DataFrame(zip(top_dois,top_cnt,word_list),columns = [\"doi\",\"cnt_of_words\",\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_of_word_with_info = score_of_word_with_info.rename({0:\"first_year\"},axis=1).sort_values(\"score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>cnt_in_all_articles</th>\n",
       "      <th>cnt_of_articles</th>\n",
       "      <th>index</th>\n",
       "      <th>first_year</th>\n",
       "      <th>quantile</th>\n",
       "      <th>doi</th>\n",
       "      <th>cnt_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mdd</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1001</td>\n",
       "      <td>284</td>\n",
       "      <td>mdd</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.1007/s40273-021-01019-4' '10.1016/j.jad.2...</td>\n",
       "      <td>[16, 12, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ocd</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>887</td>\n",
       "      <td>204</td>\n",
       "      <td>ocd</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.2196/26715' '10.3389/fpsyt.2021.677567' '...</td>\n",
       "      <td>[15, 14, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>delirium</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>2667</td>\n",
       "      <td>787</td>\n",
       "      <td>delirium</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.1186/s12912-021-00543-0' '10.1186/s13063-...</td>\n",
       "      <td>[18, 17, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rhinitis</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>870</td>\n",
       "      <td>482</td>\n",
       "      <td>rhinitis</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.2196/33941' '10.3390/jcm10143183' '10.117...</td>\n",
       "      <td>[8, 8, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ibs</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>475</td>\n",
       "      <td>113</td>\n",
       "      <td>ibs</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.53350/pjmhs211572062' '10.1111/jgh.15466'...</td>\n",
       "      <td>[14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>cobalamin</td>\n",
       "      <td>0.684859</td>\n",
       "      <td>67</td>\n",
       "      <td>26</td>\n",
       "      <td>cobalamin</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.3389/fmed.2021.807017' '10.3390/nu1306191...</td>\n",
       "      <td>[3, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>sgm</td>\n",
       "      <td>0.684791</td>\n",
       "      <td>201</td>\n",
       "      <td>46</td>\n",
       "      <td>sgm</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.1002/jia2.25728' '10.2147/dddt.s288829' '...</td>\n",
       "      <td>[14, 10, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>casp</td>\n",
       "      <td>0.684779</td>\n",
       "      <td>96</td>\n",
       "      <td>82</td>\n",
       "      <td>casp</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.3390/bioengineering9030118' '10.1002/prot...</td>\n",
       "      <td>[3, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>methodswe</td>\n",
       "      <td>0.684670</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>methodswe</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.1101/2020.12.30.20248929' '10.1101/2021.0...</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>univariate</td>\n",
       "      <td>0.684607</td>\n",
       "      <td>3564</td>\n",
       "      <td>3176</td>\n",
       "      <td>univariate</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.1186/s12874-021-01336-4' '10.1016/j.euron...</td>\n",
       "      <td>[6, 5, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            word     score  cnt_in_all_articles  cnt_of_articles       index  \\\n",
       "0            mdd  0.999959                 1001              284         mdd   \n",
       "1            ocd  0.999880                  887              204         ocd   \n",
       "2       delirium  0.999785                 2667              787    delirium   \n",
       "3       rhinitis  0.999598                  870              482    rhinitis   \n",
       "4            ibs  0.999479                  475              113         ibs   \n",
       "...          ...       ...                  ...              ...         ...   \n",
       "4995   cobalamin  0.684859                   67               26   cobalamin   \n",
       "4996         sgm  0.684791                  201               46         sgm   \n",
       "4997        casp  0.684779                   96               82        casp   \n",
       "4998   methodswe  0.684670                  129              129   methodswe   \n",
       "4999  univariate  0.684607                 3564             3176  univariate   \n",
       "\n",
       "      first_year quantile                                                doi  \\\n",
       "0         1990.0       10  ['10.1007/s40273-021-01019-4' '10.1016/j.jad.2...   \n",
       "1         2006.0       10  ['10.2196/26715' '10.3389/fpsyt.2021.677567' '...   \n",
       "2         2001.0       10  ['10.1186/s12912-021-00543-0' '10.1186/s13063-...   \n",
       "3         1977.0       10  ['10.2196/33941' '10.3390/jcm10143183' '10.117...   \n",
       "4         2003.0       10  ['10.53350/pjmhs211572062' '10.1111/jgh.15466'...   \n",
       "...          ...      ...                                                ...   \n",
       "4995      1996.0        1  ['10.3389/fmed.2021.807017' '10.3390/nu1306191...   \n",
       "4996      2013.0        1  ['10.1002/jia2.25728' '10.2147/dddt.s288829' '...   \n",
       "4997      2016.0        1  ['10.3390/bioengineering9030118' '10.1002/prot...   \n",
       "4998      2005.0        1  ['10.1101/2020.12.30.20248929' '10.1101/2021.0...   \n",
       "4999      1998.0        1  ['10.1186/s12874-021-01336-4' '10.1016/j.euron...   \n",
       "\n",
       "      cnt_of_words  \n",
       "0     [16, 12, 12]  \n",
       "1     [15, 14, 12]  \n",
       "2     [18, 17, 17]  \n",
       "3        [8, 8, 7]  \n",
       "4     [14, 14, 14]  \n",
       "...            ...  \n",
       "4995     [3, 2, 2]  \n",
       "4996   [14, 10, 9]  \n",
       "4997     [3, 3, 3]  \n",
       "4998     [1, 1, 1]  \n",
       "4999     [6, 5, 3]  \n",
       "\n",
       "[5000 rows x 9 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_fin = score_of_word_with_info.merge(fin,on=\"word\",how=\"left\")\n",
    "df_fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_fin.to_csv(\"outputs/classifier/train_2021/score_of_word_with_info.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
