{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.2.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import gensim\n",
    "import operator\n",
    "from gensim.models import Word2Vec\n",
    "import gensim.downloader as api\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.parsing.preprocessing import strip_punctuation\n",
    "print((gensim.__version__))  # needed 3.8.3   -> pip install gensim==3.8.3\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import functions\n",
    "import re\n",
    "from itertools import chain\n",
    "from collections import Counter\n",
    "import tqdm\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload sources - trained models, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_year_of_citations = 2021\n",
    "\n",
    "# which articles based on year of publication will be selected for training and testing\n",
    "min_train_year_published = 2019\n",
    "max_train_year_published = 2020\n",
    "min_pred_year_published = 2022\n",
    "max_pred_year_published = 2022\n",
    "\n",
    "embeddings_from_year = 2019\n",
    "embeddings_to_year = 2020\n",
    "\n",
    "classifier = \"lr\"  # or \"rf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all = pd.read_csv(\"outputs/df_sw_tok_low_punc_lemm_v7.csv\").rename(columns = {'doi_x':'doi'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_all_from = df_all[(df_all['Year']<=2022) & (df_all['Year']>=2021)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Upload models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lreg_w2v_avg = pickle.load(open('outputs/classifier/train_'+str(train_year_of_citations)+'/'+'lreg_w2v_avg_'+str(train_year_of_citations)+'.sav', 'rb'))\n",
    "model_w2v = gensim.models.Word2Vec.load(\"outputs/w2v/w2v_published_between_\"+str(embeddings_from_year) + \" and \"+ str(embeddings_to_year)+\".model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importance of lreg w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "82402\n"
     ]
    }
   ],
   "source": [
    "#### words of word2vec model whole dictionary - based on published articles 2019-2022 \n",
    "words = model_w2v.wv.key_to_index.keys()\n",
    "we_dict = {word:model_w2v.wv[word] for word in words}\n",
    "words_list_total = pd.DataFrame(we_dict.items())\n",
    "print(len(words_list_total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_of_word =  functions.score_of_word(model_w2v,lreg_w2v_avg).sort_values(by = [\"score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add cnt of articles and first year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_cnt_info(score_of_word, df_all, top_n = 40000):\n",
    "\n",
    "    final_results_of_select = score_of_word[score_of_word[\"word\"].isin(list(words_list_total[0].values))]\n",
    "    df_all[\"abstract_cleaned_tok\"] = functions.tokenized_column(df_all[\"abstract_cleaned\"])\n",
    "    df_all_list_of_lists = list(df_all[\"abstract_cleaned_tok\"].values)\n",
    "\n",
    "    corpus = df_all.abstract_cleaned\n",
    "    words = ' '.join(corpus)\n",
    "    output = Counter(words.split()).most_common()\n",
    "    cnt_in_all_articles = pd.DataFrame(output,columns=[\"index\",\"cnt_in_all_articles\"])\n",
    "    \n",
    "    cnt = dict(Counter(chain.from_iterable(set(l) for l in df_all_list_of_lists)))\n",
    "    cnt_articles = pd.DataFrame(cnt,index=[\"cnt_of_articles\"]).transpose().reset_index()\n",
    "    \n",
    "    final_results_of_select = pd.merge(final_results_of_select, cnt_in_all_articles, left_on=  ['word'],\n",
    "                   right_on= ['index'], \n",
    "                   how = 'left')\n",
    "    \n",
    "    final_results_of_select = pd.merge(final_results_of_select, cnt_articles, left_on=  ['word'],\n",
    "                   right_on= ['index'], \n",
    "                   how = 'left')\n",
    "    \n",
    "    final_results_of_select = final_results_of_select[[\"word\",\"score\",\"cnt_in_all_articles\",\"cnt_of_articles\"]]\n",
    "    \n",
    "    top_df = final_results_of_select[:top_n]\n",
    " \n",
    "    return top_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = add_cnt_info(score_of_word, df_all, top_n = 5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df.to_csv(\"outputs/top_df_5000.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df = pd.read_csv(\"outputs/top_df_5000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add first year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_info_wo_target_w2(top_df, df_all, top_n = 40000):\n",
    "    \n",
    "    from sklearn.feature_extraction.text import CountVectorizer\n",
    "    cvec = CountVectorizer(analyzer = \"word\", tokenizer=lambda txt: txt.split(), \n",
    "                       ngram_range=(1,1),\n",
    "                       binary= True,\n",
    "                       min_df = 3\n",
    "                      ) \n",
    "    matrix_bow_train = cvec.fit_transform(df_all['abstract_cleaned'])\n",
    "    tokens_bow_train = cvec.get_feature_names_out()\n",
    "    matrix_bow_train_pd = pd.DataFrame.sparse.from_spmatrix(matrix_bow_train, columns = tokens_bow_train,index=df_all.Year)\n",
    "    matrix_bow_train_pd = matrix_bow_train_pd[[col for col in matrix_bow_train_pd.columns if col in list(top_df.word.values)]]\n",
    "    matrix_bow_train_pd = matrix_bow_train_pd.reset_index()\n",
    "    \n",
    "    import gc\n",
    "    gc.collect()\n",
    "    import ctypes\n",
    "    libc = ctypes.CDLL(\"libc.so.6\") # clearing cache \n",
    "    libc.malloc_trim(0)\n",
    "    \n",
    "    for col in tqdm(matrix_bow_train_pd.columns[1:(int(top_n))]):\n",
    "        matrix_bow_train_pd[col] = matrix_bow_train_pd[col]*matrix_bow_train_pd['Year']\n",
    "        #matrix_bow_train_pd[col] = np.where(matrix_bow_train_pd[col]==1,matrix_bow_train_pd['Year'],0)\n",
    "        \n",
    "    matrix_bow_train_pd=matrix_bow_train_pd.mask(matrix_bow_train_pd==0)\n",
    "    matrix_bow_train_pd=matrix_bow_train_pd.fillna(10000)\n",
    "    min_df = matrix_bow_train_pd.min()\n",
    "\n",
    "    return pd.merge(top_df,min_df.reset_index(), left_on=['word'], right_on= ['index'],  how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-berl03@vse.cz/.local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n",
      "100%|██████████| 4999/4999 [00:10<00:00, 463.66it/s]\n"
     ]
    }
   ],
   "source": [
    "score_of_word_with_info = score_info_wo_target_w2(top_df, df_all, top_n = len(top_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save separetly (because of memory usage I do it separetly by 20 000 words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_of_word_with_info.to_csv(\"outputs/word_score_info_first_5000.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download all "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_of_word_with_info[\"quantile\"]=pd.cut(score_of_word_with_info.score, bins=10, right=True,labels=[\"1\",\"2\",\"3\",\"4\",\"5\",\"6\",\"7\",\"8\",\"9\",\"10\"])\n",
    "score_of_word_with_info = score_of_word_with_info.dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add relevant articles - articles with the highest number of words appeared in\n",
    "\n",
    "- from all articles 2019-2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jupyter-berl03@vse.cz/.local/lib/python3.9/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "top_df = score_of_word_with_info\n",
    "\n",
    "top_n = len(top_df)\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cvec = CountVectorizer(analyzer = \"word\", tokenizer=lambda txt: txt.split(), \n",
    "                       ngram_range=(1,1),\n",
    "                       binary= False,\n",
    "                       min_df = 1\n",
    "                      ) \n",
    "matrix_bow_train = cvec.fit_transform(df_all_from['abstract_cleaned'])\n",
    "tokens_bow_train = cvec.get_feature_names_out()\n",
    "matrix_bow_train_pd = pd.DataFrame.sparse.from_spmatrix(matrix_bow_train, columns = tokens_bow_train,index=df_all_from.doi)\n",
    "matrix_bow_train_pd = matrix_bow_train_pd[[col for col in matrix_bow_train_pd.columns if col in list(top_df.word.values)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix_bow_train_pd = matrix_bow_train_pd.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4993/4993 [01:37<00:00, 51.11it/s]\n"
     ]
    }
   ],
   "source": [
    "top_dois = []\n",
    "top_cnt = []\n",
    "word_list = []\n",
    "for col in tqdm(matrix_bow_train_pd.columns[1:(int(top_n))]):\n",
    "    top = matrix_bow_train_pd[[col]+[\"doi\"]].sort_values(col,ascending=False)[:3]\n",
    "    top_dois.append(str(top[\"doi\"].values))\n",
    "    top_cnt.append(str(list(top[col].values)))\n",
    "    word_list.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "fin = pd.DataFrame(zip(top_dois,top_cnt,word_list),columns = [\"doi\",\"cnt_of_words\",\"word\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_df.merge(fin,on=\"word\",how=\"left\").to_csv(\"word_score_info_first_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_of_word_with_info = pd.read_csv(\"word_score_info_first_all.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>word</th>\n",
       "      <th>score</th>\n",
       "      <th>cnt_in_all_articles</th>\n",
       "      <th>cnt_of_articles</th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>quantile</th>\n",
       "      <th>doi</th>\n",
       "      <th>cnt_of_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>mdd</td>\n",
       "      <td>0.999959</td>\n",
       "      <td>1001</td>\n",
       "      <td>284</td>\n",
       "      <td>mdd</td>\n",
       "      <td>1990.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.1007/s40273-021-01019-4' '10.1016/j.jad.2...</td>\n",
       "      <td>[16, 12, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>ocd</td>\n",
       "      <td>0.999880</td>\n",
       "      <td>887</td>\n",
       "      <td>204</td>\n",
       "      <td>ocd</td>\n",
       "      <td>2006.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.2196/26715' '10.3389/fpsyt.2021.677567' '...</td>\n",
       "      <td>[15, 14, 12]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>delirium</td>\n",
       "      <td>0.999785</td>\n",
       "      <td>2667</td>\n",
       "      <td>787</td>\n",
       "      <td>delirium</td>\n",
       "      <td>2001.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.1186/s12912-021-00543-0' '10.1186/s13063-...</td>\n",
       "      <td>[18, 17, 17]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>rhinitis</td>\n",
       "      <td>0.999598</td>\n",
       "      <td>870</td>\n",
       "      <td>482</td>\n",
       "      <td>rhinitis</td>\n",
       "      <td>1977.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.2196/33941' '10.3390/jcm10143183' '10.117...</td>\n",
       "      <td>[8, 8, 7]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>ibs</td>\n",
       "      <td>0.999479</td>\n",
       "      <td>475</td>\n",
       "      <td>113</td>\n",
       "      <td>ibs</td>\n",
       "      <td>2003.0</td>\n",
       "      <td>10</td>\n",
       "      <td>['10.53350/pjmhs211572062' '10.1111/jgh.15466'...</td>\n",
       "      <td>[14, 14, 14]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>4995</td>\n",
       "      <td>4995</td>\n",
       "      <td>cobalamin</td>\n",
       "      <td>0.684859</td>\n",
       "      <td>67</td>\n",
       "      <td>26</td>\n",
       "      <td>cobalamin</td>\n",
       "      <td>1996.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.3389/fmed.2021.807017' '10.3390/nu1306191...</td>\n",
       "      <td>[3, 2, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>4996</td>\n",
       "      <td>4996</td>\n",
       "      <td>sgm</td>\n",
       "      <td>0.684791</td>\n",
       "      <td>201</td>\n",
       "      <td>46</td>\n",
       "      <td>sgm</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.1002/jia2.25728' '10.2147/dddt.s288829' '...</td>\n",
       "      <td>[14, 10, 9]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>4997</td>\n",
       "      <td>4997</td>\n",
       "      <td>casp</td>\n",
       "      <td>0.684779</td>\n",
       "      <td>96</td>\n",
       "      <td>82</td>\n",
       "      <td>casp</td>\n",
       "      <td>2016.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.3390/bioengineering9030118' '10.1002/prot...</td>\n",
       "      <td>[3, 3, 3]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>4998</td>\n",
       "      <td>4998</td>\n",
       "      <td>methodswe</td>\n",
       "      <td>0.684670</td>\n",
       "      <td>129</td>\n",
       "      <td>129</td>\n",
       "      <td>methodswe</td>\n",
       "      <td>2005.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.1101/2020.12.30.20248929' '10.1101/2021.0...</td>\n",
       "      <td>[1, 1, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>4999</td>\n",
       "      <td>4999</td>\n",
       "      <td>univariate</td>\n",
       "      <td>0.684606</td>\n",
       "      <td>3564</td>\n",
       "      <td>3176</td>\n",
       "      <td>univariate</td>\n",
       "      <td>1998.0</td>\n",
       "      <td>1</td>\n",
       "      <td>['10.1186/s12874-021-01336-4' '10.1016/j.euron...</td>\n",
       "      <td>[6, 5, 3]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0.1  Unnamed: 0        word     score  cnt_in_all_articles  \\\n",
       "0                0           0         mdd  0.999959                 1001   \n",
       "1                1           1         ocd  0.999880                  887   \n",
       "2                2           2    delirium  0.999785                 2667   \n",
       "3                3           3    rhinitis  0.999598                  870   \n",
       "4                4           4         ibs  0.999479                  475   \n",
       "...            ...         ...         ...       ...                  ...   \n",
       "4995          4995        4995   cobalamin  0.684859                   67   \n",
       "4996          4996        4996         sgm  0.684791                  201   \n",
       "4997          4997        4997        casp  0.684779                   96   \n",
       "4998          4998        4998   methodswe  0.684670                  129   \n",
       "4999          4999        4999  univariate  0.684606                 3564   \n",
       "\n",
       "      cnt_of_articles       index       0  quantile  \\\n",
       "0                 284         mdd  1990.0        10   \n",
       "1                 204         ocd  2006.0        10   \n",
       "2                 787    delirium  2001.0        10   \n",
       "3                 482    rhinitis  1977.0        10   \n",
       "4                 113         ibs  2003.0        10   \n",
       "...               ...         ...     ...       ...   \n",
       "4995               26   cobalamin  1996.0         1   \n",
       "4996               46         sgm  2013.0         1   \n",
       "4997               82        casp  2016.0         1   \n",
       "4998              129   methodswe  2005.0         1   \n",
       "4999             3176  univariate  1998.0         1   \n",
       "\n",
       "                                                    doi  cnt_of_words  \n",
       "0     ['10.1007/s40273-021-01019-4' '10.1016/j.jad.2...  [16, 12, 12]  \n",
       "1     ['10.2196/26715' '10.3389/fpsyt.2021.677567' '...  [15, 14, 12]  \n",
       "2     ['10.1186/s12912-021-00543-0' '10.1186/s13063-...  [18, 17, 17]  \n",
       "3     ['10.2196/33941' '10.3390/jcm10143183' '10.117...     [8, 8, 7]  \n",
       "4     ['10.53350/pjmhs211572062' '10.1111/jgh.15466'...  [14, 14, 14]  \n",
       "...                                                 ...           ...  \n",
       "4995  ['10.3389/fmed.2021.807017' '10.3390/nu1306191...     [3, 2, 2]  \n",
       "4996  ['10.1002/jia2.25728' '10.2147/dddt.s288829' '...   [14, 10, 9]  \n",
       "4997  ['10.3390/bioengineering9030118' '10.1002/prot...     [3, 3, 3]  \n",
       "4998  ['10.1101/2020.12.30.20248929' '10.1101/2021.0...     [1, 1, 1]  \n",
       "4999  ['10.1186/s12874-021-01336-4' '10.1016/j.euron...     [6, 5, 3]  \n",
       "\n",
       "[5000 rows x 11 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_of_word_with_info.sort_values(\"score\",ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_of_word_with_info.to_csv(\"sc_5000.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
